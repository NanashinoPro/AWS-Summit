<<<<<<< HEAD
### 1. 開催概要
| 項目 | 内容 |
| :--- | :---------- |
| **セッション名** | 実社会のセキュリティを支える生成 AI 活用ユースケース |
| **日時** | 2025年6月26日 15:50 |
| **発表者** | 勝原 達也 (アマゾン ウェブ サービス ジャパン合同会社 シニアセキュリティソリューションアーキテクト) |
| **概要** | 本セッションは、生成AIを単なるバズワードではなく、実社会におけるセキュリティを支えるための具体的な「ツール」として捉え、その活用方法を解説するものである。インシデント対応、コンプライアンス、脅威分析などのユースケースについて、アーキテクチャやデモを交えながら、セキュリティ業務を自動化・効率化する手法が紹介された。 |

### 2. 主要なポイント

#### 生成AI活用の基本姿勢
生成AIはソリューションそのものではなく、セキュリティチームの労力を軽減し、より重要な活動に集中することを可能にする非常に優れた「ツール」であると位置づけられている。その目的は、単純作業の自動化と、スキルレベルの異なる担当者の専門能力向上を支援することにある。広範なトレーニングや専門知識がなくとも、すぐに活用を始められる点が強調された。

#### 導入における考慮事項
生成AIをシステムに組み込む際には、以下の課題を考慮する必要がある。
* **ハルシネーション**: 事実に基づかない情報を生成する可能性。
* **プライバシー**: 機微なデータやプライバシー情報の取り扱い。
* **品質保証**: 生成されるアウトプットの一貫性と正確性の担保。
* **過剰な代理行為**: 人間が意図しない範囲までAIが処理を実行してしまう問題。

#### 5つの具体的な活用ユースケース
本セッションでは、セキュリティの現場における5つの具体的なユースケースがデモを交えて紹介された。

**1. セキュリティインシデント対応の効率化**
* **課題**: インシデント対応者が膨大なログデータから状況を把握し、対策を講じるためには高度なクエリ作成能力や専門知識が求められ、時間がかかる。
* **解決策**: 自然言語による指示で、調査・分析に必要なクエリや対応手順をまとめたランブック（スクリプト）を生成AIに作成させる。これにより、インシデントの修復にかかる時間を短縮する。
* **アーキテクチャ例**: AWS Security Hubの検知結果をAmazon Bedrockが解釈し、Amazon SageMaker上のNotebookで実行可能な対応コード（Boto3）を生成する。
* **ポイント**: モデルの`temperature`パラメータを`0`に設定することで、応答のランダム性を抑制し、一貫性のある結果を得ることが重要である。

**2. コンプライアンス業務の自動化（SBOM生成）**
* **課題**: 米国大統領令や金融業界などで要求され始めているSBOM（Software Bill of Materials）の作成は、手作業では膨大な手間がかかる。
* **解決策**: AWS Systems Managerで収集したEC2インスタンス等のソフトウェア構成情報を、生成AIを用いてCycloneDXなどの標準フォーマットのSBOMに自動変換する。
* **アーキテクチャ例**: Amazon SageMakerからBoto3経由でAWS Systems Managerのインベントリ情報を取得し、Amazon BedrockでSBOM形式に変換・出力する。

**3. ルールやセキュリティテスト作成の迅速化**
* **課題**: 脆弱性の調査やセキュリティテストの作成・実行は、スレットハンターやテスターにとって手間のかかる作業である。
* **解決策**: Amazon Q Developerのようなツールを用い、自然言語で指示することでテストコードを自動生成し、作業を迅速化する。
* **ポイント**: 生成されたコードは鵜呑みにせず、必ず人間がレビューし、テストすることが不可欠である。また、自動修復スクリプトを実行する際には、人間による明示的な「承認」のステップを組み込むことで、過剰な代理行為を防ぐことができる。

**4. セキュリティチームの能力拡張（セキュリティチャットボット）**
* **課題**: 開発者からのセキュリティポリシーに関する問い合わせがセキュリティ担当者に集中し、ボトルネックとなりがちである。
* **解決策**: 社内ドキュメントやポリシーを学習させたセキュリティ特化のチャットボットをAmazon Q Businessで構築する。これにより、開発者は自己解決が可能になり、セキュリティチームはより専門的な業務に集中できる。
* **アーキテクチャ例**: S3に格納したポリシー文書をAmazon Q Businessに連携させることで、社内情報に基づいた回答を生成し、ハルシネーションを抑制する。

**5. デセプション（おとり）プラットフォームの構築**
* **課題**: 攻撃者の手口を調査するための従来のハニーポットなどは、準備や維持に手間がかかる。
* **解決策**: 生成AIを用いて、攻撃者に対しリアルタイムで本物らしい「偽のデータ」を生成して提供する、より高度なおとり（デセプション）環境を構築する。
* **アーキテクチャ例**: AWS WAFで攻撃者と判断したトラフィックに対し、Amazon Bedrockが偽のデータを生成して返す仕組みを構築する。これにより、攻撃者の手口を安全に分析することが可能となる。

#### まとめと提言
生成AIは人間にとって代わるものではなく、セキュリティ専門家の生産性を最大化するための強力なツールである。使い慣れたAWSのアーキテクチャ上で安全に活用を開始できるため、AIの専門家でなくとも、まずは実験的にでも「今すぐ始める」ことが推奨された。
=======
# 実社会のセキュリティを支える生成 AI 活用ユースケース

## 日時
2025/6/26 15:50

## 発表者
勝原 達也

アマゾン ウェブ サービス ジャパン合同会社
シニアセキュリティソリューションアーキテクト

## abstract
実社会における生成 AI のユースケースはたくさんありますが、セキュリティの改善ではどうでしょうか。このセッションでは、インシデント対応、コンプライアンス要件への対応、脅威分析などの具体的なユースケースに関するアーキテクチャやデモを通じて、セキュリティ業務を自動化・効率化するために生成 AI を活用する方法を学んでいただけます。

## 概要メモ
- コーディングはできること前提
- 乗るしかないこのビッグウェーブw
- 生成AIをバズワードにしてはならない
- 生成AIを活用したセキュリティに焦点
- 生成AIはツール、ソリューションではない
- 単純なものは自動化させたい
- 全ての専門能力に高い人物ばかりではない
- 専門能力の向上に生成AIを活用
- ハルシネーション：ソリューションに組み込む時は難しい
- データのプライバシー
- 過剰な代理行為
  - 本来人間がアクセスできる範囲を超えて処理できてしまう問題
- リアルな実態をお届け
  - デモでうまくいかないことも
- ユースケース
  - セキュリティインシデント
    - インシデントレスポンダー
      - 熟練なエンジニアではない
        - クエリを書きにくい
    - AIにクエリを作ってもらって調査分析のスピードをあげよう
    - ランブック
      - 利点：自然言語で作成できる
      - ランダムな応答を抑える
      - スロットを回しても必ず大当たりになるようにする
    - デモ
      - EC２に過剰なSGが適用されていた
      - Security Hubで膨大なJSON
      - ランブックでJSONから必要な情報を抽出する
      - 修正するスクリプトを作成する
        - 処理の概要も書かれている
      - 処理を確認する
      - ルールを変更するスクリプトを作成する
      - コードは書いていないんだけど、できちゃう
  - コンプライアンス対応
    - SBOM：ソフトウェアの構成や部品を一覧化したもの
      - 米国：大統領令でやれと言われている
      - 金融業界でも出始めている
      - 脆弱性管理に役立つ
      - フォーマットが重要
        - CyclonDX
    - SBOMを生成AIに作らせよう
    - デモ
      - SSMから取得して
      - サイクロンフォーマットに変換して
      - 何も調整せずにできちゃった！
  - セキュリティチェックシートへの回答
    - 独自の言い回しがあるため、未熟な人には困難な作業
    - RAGを活用
    - デモ
      - API Gatewayが特定のコンプラを守れているか→解凍してくれる
      - AC-3の独特の用語を解凍してくれる：ページ番号も取得してくれる
      - 大量の文章から文脈にあった部分を特定してくれる
  - セキュリティテストの自動生成
    - Amazon Q Developerをしよう
    - SGがフルオープンになっていないかを検査する
    - デモ1
      - 自分の環境を全て洗い出させる
      - 自分で必ず実行してみる←重要
      - エラーが起きたらAmazon Qにきく
        - コードを修正してもらう
      - コンソールにログが出てくるように！
      - オープンなSGがあればWarning、txtやcsvに出力
      - 無事に最後まで流れていったように見える
      - csv：適切に実装
      - txt：コンソールの内容を出力、WARNIGも出力してくれる
    - デモ2
      - 修正すべきSGを特定して、修正する
      - スクリプトをレビューしてテストする
        - 鵜呑みにしない
      - OCSF形式で出力するように設定
      - 人による明示的な承認を入れることで、人が介在する
      - きちんとポリシーの修正が行われた！
    - 見積もりの会議をしている間に、作業ができちゃう状態にある
    - デモ3
      - プロンプト：色々頑張った
        - Inspector2 APIを明示したり
        - 期間の意味を指示しなかった←言葉、意味、文脈をきちんと伝えないといけない
      - Amazon Q Developerがコード生成
      - エラーが発生
      - エラーをAmazon Qにきく
      - 修正スクリプトが出力、エラーの内容を説明してくれるので勉強にもなる
      - エラーなし
      - csvに出力：期待した動きじゃない
      - Amazon Qに伝える
      - 別のスクリプトを生成
      - 完成
  - セキュリティチームの能力を拡張する
    - 中央集権的
    - セキュリティ担当者がボトルネックに→自己解決してもらう
    - Amazon Q Business
    - デモ
      - 社内のポリシーを参照して回答、ハルシネーションのぼうし
      - 開発ルールについて質問
        - 認証情報のポリシーについて回答した方がいいと理解して定時
        - 質問の中身に応じて適切なデータを抽出してくれる
      - 可処分時間が生まれる
  - 生成AIを囮にするプラットフォーム
    - 細かいところはぼかしている
    - 自社のアプリケーションを守る人たち
    - 高いリスク許容度が必要
    - 攻撃者の手口がわかるメリットが多い組織に有効
    - これまで：HoneyPot
    - 生成AIを使ってよりプロアクティブに
    - Feed the bear
      - 生成AIを使って偽データを渡す
      - 同じ偽データをキャッシュとして保存
      - デモ
        - ノートブックを攻撃者
        - DynamoDBにデータを登録済み
        - API GatewayとLambda関数
          - Lambdaに偽のデータを作成するプロンプト
        - 自分のデータはきちんと返して、別のデータは偽物を返す←どうして！？
- まとめ
  - 今すぐ実験を始めてほしい
    - AIの専門家じゃなくてもできちゃうもの
    - 
>>>>>>> c4022de53fd400287e7b5dcadd1ad68adbe05274
